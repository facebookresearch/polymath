from agent.logic.engine_strategy import EngineStrategy

from inference.client import InferenceClient
from inference.chat_compeletion import Message, Role

class ErrorHandler:
    """
    Handles error-aware prompting when a logic problem fails to be solved correctly.
    This component formats the error feedback and produces a specialized prompt that
    informs the LLM of the failure. It also adjusts the temperature to encourage
    more diverse generations when necessary.
    """

    def __init__(
        self,
        engine_strategy: EngineStrategy,
        client: InferenceClient,
        max_num_retries: int = 1,
        max_temperature: float = 0.9,
        temperature_step: float = 0.3,
    ):
        """
        Initializes the ErrorHandler.

        Args:
            engine_strategy (EngineStrategy): Strategy used to generate the prompt format
            client (InferenceClient): Client used to interact with the LLM.
            max_num_retries (int): Number of times to retry the same prompt before increasing temperature.
            max_temperature (float): Maximum temperature allowed for generation.
            temperature_step (float): Step by which to increase temperature after failed retries.
        """
        self.engine_strategy = engine_strategy
        self.client = client
        self.max_num_retries = max_num_retries
        self.max_temperature = max_temperature
        self.temperature_step = temperature_step
        self.num_retry = 0
        self.curr_temperature = 0.0

    async def revise(self, code: str, error_details: str):
        """
        Sends an error-aware correction prompt to the LLM based on the provided
        faulty code and the error encountered during execution.

        Args:
            code (str): The code generated by the LLM that failed.
            error_details (str): A detailed explanation of the error or failure.
        """
        self.on_failure()
        prompt = self.engine_strategy.get_error_prompt(code, error_details)
        message = Message(Role.USER, prompt)
        _, ai_response = await self.client.create(message)
        self.client.add_message(ai_response, Role.USER)

    def on_failure(self) -> bool:
        """
        Handles failure tracking and temperature increase logic.
        Used to determine whether additional retries should be made.

        Returns:
            bool: True if another attempt should be made; False if temperature limit is reached.
        """
        if self.num_retry >= self.max_num_retries:
            if self.curr_temperature < self.max_temperature:
                self.curr_temperature += self.temperature_step
                self.client.set_temperature(self.curr_temperature)
                self.num_revise = 0
            else:
                self.reset()
                return False

        self.num_retry += 1
        return True

    def reset(self) -> None:
        """
        Resets the retry counter and temperature settings.
        """
        self.num_revise = 0
        self.curr_temperature = 0.0
        self.client.reset_temperature()
